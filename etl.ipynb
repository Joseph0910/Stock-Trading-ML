{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["XZwwhVhyNfWg","fTMAkFpeZG-5","XpnI5weCZI7A","MjJoaMJTuKME","RkEdJts_14Gr","zCdqGVd-rkdp","mkNNNviQXrle","u16lNSwe6XFD","iC9y7j8CluxL","_0bJ1BN2K7ov","t2gGRtXUpCws","U49cFdJXH-KJ","0rU6XWqE9hyq","Ka7cQ6N49-NK","JOBAWnye-MlE"],"toc_visible":true,"authorship_tag":"ABX9TyM6P5AmJm+GB5z+URKgmy3Q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Connect to GDrive"],"metadata":{"id":"XZwwhVhyNfWg"}},{"cell_type":"code","source":["### Grab 1 year of data first ####"],"metadata":{"id":"O5vGIyVtC9XM"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e97hZJyINQP4"},"outputs":[],"source":["!pip install import-ipynb japanese-candlestick marketprofile ta\n","from google.colab import drive, auth\n","import import_ipynb, sys, pandas, requests, datetime, bs4, json,pandas_datareader, market_profile, ta\n","from google.auth import default\n","from pandas_datareader.nasdaq_trader import get_nasdaq_symbols\n","from pandas.tseries.offsets import BDay\n","import patterns     # candlesticks\n","from patterns import *\n","from market_profile import MarketProfile\n","from ta import add_all_ta_features    # technical indicators\n","from ta.utils import dropna\n","from bs4 import BeautifulSoup\n","from dateutil import parser\n","import yfinance as yf\n","\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/Small Caps/Database\n","path_to_module = '/content/drive/MyDrive/Small Caps/Database'\n","sys.path.append(path_to_module)\n","auth.authenticate_user()\n","creds, _ = default()"]},{"cell_type":"markdown","source":["# Symbols List"],"metadata":{"id":"fTMAkFpeZG-5"}},{"cell_type":"code","source":["symbols = pandas_datareader.nasdaq_trader.get_nasdaq_symbols()\n","symbols['length'] = symbols['NASDAQ Symbol'].apply(lambda a: len(str(a)))\n","symbols['dot'] = symbols['NASDAQ Symbol'].apply(lambda a: 0 if str(a).find('.') == -1 else 1)\n","symbols = symbols[(symbols.length < 5) & (symbols['dot'] == 0)]\n","symbols = symbols['NASDAQ Symbol']\n","symbols = symbols[20:22]"],"metadata":{"id":"wJqc-DEDSf5X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Tables 1-2 : Technical Data"],"metadata":{"id":"XpnI5weCZI7A"}},{"cell_type":"code","source":["dailytable, intratable = pandas.DataFrame(), pandas.DataFrame()\n","\n","for symbol in symbols:\n","\n","  # connect to Yahoo Finance API\n","  headers = {\"X-RapidAPI-Key\": \"1a4e1671fdmsh8b109f9960abd33p10d082jsnf2ee61df8b81\",\"X-RapidAPI-Host\": \"apidojo-yahoo-finance-v1.p.rapidapi.com\"}\n","  url = \"https://apidojo-yahoo-finance-v1.p.rapidapi.com/stock/v2/get-chart\"\n","\n","  # daily data\n","  querystring = {\"interval\":'1d',\"symbol\": symbol,\"range\":'1y',\"region\":\"US\"}\n","  response = requests.get(url, headers=headers, params=querystring).json()\n","\n","  # variables\n","  today = datetime.datetime.today()\n","  ipo = datetime.datetime.fromtimestamp(response['chart']['result'][0]['meta']['firstTradeDate'])\n","  ex = response['chart']['result'][0]['meta']['exchangeName']\n","  curr = response['chart']['result'][0]['meta']['currency']\n","  v = response['chart']['result'][0]['indicators']['quote'][0]['volume'][-1]\n","  h = response['chart']['result'][0]['indicators']['quote'][0]['high'][-1]\n","  c = response['chart']['result'][0]['indicators']['quote'][0]['close'][-1]\n","  dv = v * c\n","  o = response['chart']['result'][0]['indicators']['quote'][0]['open'][-1]\n","  l = response['chart']['result'][0]['indicators']['quote'][0]['low'][-1]\n","  a_c = response['chart']['result'][0]['indicators']['adjclose'][0]['adjclose'][-1]\n","  pc = response['chart']['result'][0]['indicators']['quote'][0]['close'][-2]\n","  h_52wk = max(response['chart']['result'][0]['indicators']['quote'][0]['high'])\n","  l_52wk = min(response['chart']['result'][0]['indicators']['quote'][0]['low'])\n","  on_gap = (o/pc) - 1\n","  close_vs_high = (c/h) - 1\n","  close_vs_low = (c/l) - 1\n","  candle_clr = 'G' if c >= o else 'R'\n","  daily_move = (c/pc) - 1\n","  daily_range = (h/l) - 1\n","\n","  # convert to dataframe\n","  data = pandas.DataFrame(\n","  {'ticker': symbol,\n","   'ipo_date': ipo.date(),\n","   'exchange': ex,\n","   'currency' : curr,\n","   'datefield': today.date(),\n","   'volume': v,\n","   'dollar_volume': dv,\n","   'high': h,\n","   'open': o,\n","   'low': l,\n","   'close': c,\n","   'adj_close': a_c,\n","   'prev_close': pc,\n","   'high_52wk': h_52wk,\n","   'low_52wk': l_52wk,\n","   'on_gap': on_gap,\n","   'close_vs_high': close_vs_high,\n","   'close_vs_low': close_vs_low,\n","   'candle_colour' : candle_clr,\n","   'daily_move': daily_move,\n","   'daily_range': daily_range\n","  },index = [0])\n","\n","  # intraday data\n","  querystring = {\"interval\":'1m',\"symbol\": symbol,\"range\":'1d',\"region\":\"US\"}\n","  response = requests.get(url, headers=headers, params=querystring).json()\n","\n","  # variables\n","  dt1 = response['chart']['result'][0]['timestamp']\n","  dt = []\n","  for i in dt1:\n","    dt.append(datetime.datetime.fromtimestamp(i))\n","\n","  vol = response['chart']['result'][0]['indicators']['quote'][0]['volume']\n","  high = response['chart']['result'][0]['indicators']['quote'][0]['high']\n","  open = response['chart']['result'][0]['indicators']['quote'][0]['open']\n","  low = response['chart']['result'][0]['indicators']['quote'][0]['low']\n","  close = response['chart']['result'][0]['indicators']['quote'][0]['close']\n","  cndl_clr = 'G' if close >= open else 'R'\n","\n","  dollar_vol = []\n","  for i in range(0, len(vol)):\n","    try:\n","      dollar_vol.append(close[i] * vol[i])\n","    except:\n","      dollar_vol.append(-1)\n","\n","  # convert to dataframe\n","  i_data = pandas.DataFrame(\n","    {'ticker': symbol,\n","     'datefield': dt,\n","     'volume': vol,\n","     'dollar_volume' : dollar_vol,\n","     'high': high,\n","     'open': open,\n","     'low': low,\n","     'close': close,\n","     'candle_colour' : cndl_clr\n","    })\n","\n","  i_data['prev_close'] = i_data.close.shift(periods = 1)\n","  i_data['cndl_move'] = (i_data.close/i_data.prev_close) - 1\n","  i_data['cndl_range'] = (i_data.high/i_data.low) - 1\n","  i_data['shorts_HOD_volume'] = i_data.volume[i_data.high == i_data.high.max()]\n","  i_data['dip_long_volume'] = i_data.volume[i_data.low == i_data.low.min()]\n","  i_data['pv'] = ((i_data.high + i_data.low + i_data.close) / 3) * i_data.volume\n","  i_data['pv_sum'] = i_data.pv.cumsum()\n","  i_data['vol_cumsum'] = i_data.volume.cumsum()\n","  i_data['vwap_cum'] = i_data.pv_sum / i_data.vol_cumsum\n","  i_data = i_data.drop(columns = ['pv','pv_sum','vol_cumsum'])\n","\n","  # Grab intraday only (time conversion to EST ?)\n","  i_data = i_data[i_data.datefield >= datetime.datetime(today.year,today.month,today.day,9,0,0)]\n","\n","  # Append each ticker onto master table\n","  dailytable = dailytable.append(data)\n","  intratable = intratable.append(i_data)\n","\n","dailytable = dailytable[['ticker','ipo_date','exchange','currency','datefield','volume','dollar_volume','high',\n","                         'open','low','close','adj_close','prev_close','high_52wk','low_52wk','on_gap','close_vs_high',\n","                         'close_vs_low','candle_colour','daily_move','daily_range']]\n","\n","intratable = intratable[['ticker','datefield','volume','dollar_volume','high','open','low','close','candle_colour','prev_close',\n","                   'cndl_move','cndl_range','shorts_HOD_volume','dip_long_volume','vwap_cum']]\n","\n","# Append master tables to production tables\n","key_statistics = pandas.read_excel(\"key_statistics.xlsx\")\n","if max(key_statistics.datefield) != max(dailytable.datefield):\n","  key_statistics = key_statistics.append(dailytable)\n","  key_statistics.to_excel(\"key_statistics.xlsx\")\n","\n","intraday_data = pandas.read_excel(\"intraday_data.xlsx\")\n","if max(intraday_data.datefield) != max(intratable.datefield):\n","  intraday_data = intraday_data.append(intratable)\n","\n","    # Last 30 Days\n","  intraday_data = intraday_data[intraday_data.datefield >= today - BDay(20)]\n","  intraday_data.to_excel(\"intraday_data.xlsx\")"],"metadata":{"id":"rgVoqveuOd8m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Table 3: Financial Data"],"metadata":{"id":"MjJoaMJTuKME"}},{"cell_type":"code","source":["financial_stats = pandas.DataFrame()\n","\n","for symbol in symbols:\n","  url = \"https://apidojo-yahoo-finance-v1.p.rapidapi.com/stock/v3/get-statistics\"\n","  querystring = {\"symbol\": symbol,\"region\":\"US\",\"lang\":\"en-US\",\"straddle\":\"true\"}\n","  headers = {\"X-RapidAPI-Key\": \"1a4e1671fdmsh8b109f9960abd33p10d082jsnf2ee61df8b81\",\"X-RapidAPI-Host\": \"apidojo-yahoo-finance-v1.p.rapidapi.com\"}\n","  response = requests.get(url, headers=headers, params=querystring).json()\n","\n","  if response != {}:\n","    table1 = pandas.DataFrame(response['defaultKeyStatistics']).iloc[0]\n","    table2 = pandas.DataFrame(response['price']).iloc[0]\n","    table3 = pandas.DataFrame(response['financialData']).iloc[0]\n","    table4 = pandas.DataFrame(response['calendarEvents']).iloc[0]\n","    table4 = table4[['dividendDate','earnings']]\n","    table4.earnings = table4.earnings[0]['fmt']\n","    table5 = pandas.DataFrame(response['summaryDetail']).iloc[0]\n","    table6 = pandas.concat([table1,table2,table3,table4,table5])\n","    table6 = pandas.DataFrame(table6).T\n","    financial_stats = financial_stats.append(table6)\n","\n","financial_stats['datefield'] = datetime.date.today()\n","\n","# convert from timestamp to datefield\n","columns_to_convert = ['lastFiscalYearEnd','nextFiscalYearEnd','mostRecentQuarter','sharesShortPreviousMonthDate','lastSplitDate','lastDividendDate',\n","                      'dateShortInterest','regularMarketTime','postMarketTime','preMarketTime','exDividendDate','dividendDate']\n","\n","for col in columns_to_convert:\n","  try:\n","    financial_stats[col] = financial_stats[col].apply(lambda a: datetime.datetime.fromtimestamp(a))\n","  except:\n","    financial_stats[col] = datetime.datetime(1901,1,1,11,59,59)\n","\n","fin_stats = financial_stats.T.drop_duplicates().T # remove duplicate columns\n","\n","# Append master table to production table\n","financial_stats = pandas.read_excel(\"financial_stats.xlsx\")\n","financial_stats = financial_stats.append(fin_stats)\n","financial_stats.to_excel(\"financial_stats.xlsx\")"],"metadata":{"id":"kW5CZrjxuN8v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Table 4-8: Summary, Fund, Institution, Insider Data"],"metadata":{"id":"RkEdJts_14Gr"}},{"cell_type":"code","source":["for symbol in symbols:\n","  url = \"https://apidojo-yahoo-finance-v1.p.rapidapi.com/stock/v2/get-summary\"\n","  querystring = {\"symbol\": symbol ,\"region\":\"US\"}\n","  headers = {\"X-RapidAPI-Key\": \"1a4e1671fdmsh8b109f9960abd33p10d082jsnf2ee61df8b81\",\"X-RapidAPI-Host\": \"apidojo-yahoo-finance-v1.p.rapidapi.com\"}\n","  response = requests.get(url, headers=headers, params=querystring).json()\n","\n","  # fund ownership\n","  fund_table = []\n","  for i in range(0,len(response['fundOwnership']['ownershipList'])):\n","    r = response['fundOwnership']['ownershipList'][i]['reportDate']['raw']\n","    o = response['fundOwnership']['ownershipList'][i]['organization']\n","    h = response['fundOwnership']['ownershipList'][i]['pctHeld']['raw']\n","    p = response['fundOwnership']['ownershipList'][i]['position']['raw']\n","    v = response['fundOwnership']['ownershipList'][i]['value']['raw']\n","    c = response['fundOwnership']['ownershipList'][i]['pctChange']['raw']\n","    fund_table.append((r,o,h,p,v,c))\n","\n","  fund_table_df = pandas.DataFrame(fund_table,columns = ['reportDate','organization','holding','position','value','change'])\n","  fund_table_df['reportDate'] = fund_table_df.reportDate.apply(lambda a: datetime.datetime.fromtimestamp(a))\n","  fund_table_df = fund_table_df.sort_values(by = 'reportDate', ascending = False)\n","  fund_table_df = fund_table_df[fund_table_df.reportDate == max(fund_table_df.reportDate)]\n","  fund_table_df['symbol'] = symbol\n","  fund_table_df['datefield'] = datetime.date.today()\n","\n","  # insider transactions\n","  ins_table = []\n","  for i in range(0,len(response['insiderTransactions']['transactions'])):\n","    f = response['insiderTransactions']['transactions'][i]['filerName']\n","    t = response['insiderTransactions']['transactions'][i]['transactionText']\n","    o = response['insiderTransactions']['transactions'][i]['ownership']\n","    d = response['insiderTransactions']['transactions'][i]['startDate']['raw']\n","    v = response['insiderTransactions']['transactions'][i]['value']['raw']\n","    p = response['insiderTransactions']['transactions'][i]['filerRelation']\n","    s = response['insiderTransactions']['transactions'][i]['shares']['raw']\n","    ins_table.append((f,t,o,d,v,p,s))\n","\n","  ins_table_df = pandas.DataFrame(ins_table,columns = ['insider_name','insider_trans','insider_own','insider_date','insider_value','insider_pos','insider_shrs'])\n","  ins_table_df['insider_date'] = ins_table_df.insider_date.apply(lambda a: datetime.datetime.fromtimestamp(a))\n","  ins_table_df = ins_table_df.sort_values(by = 'insider_date', ascending = False)\n","  ins_table_df = ins_table_df[ins_table_df.insider_date == max(ins_table_df.insider_date)]\n","  ins_table_df['symbol'] = symbol\n","  ins_table_df['datefield'] = datetime.date.today()\n","\n","  # convert to dataframe\n","  sum_data = pandas.DataFrame(\n","    { 'symbol': symbol,\n","      'datefield': datetime.date.today(),\n","      'sector': response['summaryProfile']['sector'],\n","      'city': response['summaryProfile']['city'],\n","      'state': response['summaryProfile']['state'],\n","      'industry': response['summaryProfile']['industry']\n","    },index = [0])\n","\n","# Insider Transactions\n","hold_table = []\n","for i in range(0,len(response['insiderHolders']['holders'])):\n","  n = response['insiderHolders']['holders'][i]['name']\n","  r = response['insiderHolders']['holders'][i]['relation']\n","  d = response['insiderHolders']['holders'][i]['transactionDescription']\n","  t = response['insiderHolders']['holders'][i]['latestTransDate']['raw']\n","  try:\n","    p = response['insiderHolders']['holders'][i]['positionDirect']['raw']\n","  except:\n","    p = -1\n","  try:\n","    dd = response['insiderHolders']['holders'][i]['positionDirectDate']['raw']\n","  except:\n","    dd = 0\n","  hold_table.append((n,r,d,t,p,dd))\n","\n","  hold_table_df = pandas.DataFrame(hold_table,columns = ['holder_name','holder_pos','holder_trx','trx_date','holder_value','holder_date'])\n","  hold_table_df['trx_date'] = hold_table_df.trx_date.apply(lambda a: datetime.datetime.fromtimestamp(a))\n","  hold_table_df['holder_date'] = hold_table_df.holder_date.apply(lambda a: datetime.datetime.fromtimestamp(a))\n","  hold_table_df = hold_table_df[hold_table_df.trx_date == max(hold_table_df.holder_date)]\n","  hold_table_df['symbol'] = symbol\n","  hold_table_df['datefield'] = datetime.date.today()\n","\n","# Instutition Ownership\n","inst_table = []\n","for i in range(0,len(response['institutionOwnership']['ownershipList'])):\n","  d = response['institutionOwnership']['ownershipList'][i]['reportDate']['raw']\n","  o = response['institutionOwnership']['ownershipList'][i]['organization']\n","  p = response['institutionOwnership']['ownershipList'][i]['pctHeld']['raw']\n","  h = response['institutionOwnership']['ownershipList'][i]['position']['raw']\n","  v = response['institutionOwnership']['ownershipList'][i]['value']['raw']\n","  c = response['institutionOwnership']['ownershipList'][i]['pctChange']['raw']\n","  inst_table.append((d,o,p,h,v,c))\n","\n","inst_table_df = pandas.DataFrame(inst_table,columns = ['reportDate','institution','inst_pctHeld','inst_pos','inst_value','inst_pctChange'])\n","inst_table_df['reportDate'] = inst_table_df.reportDate.apply(lambda a: datetime.datetime.fromtimestamp(a))\n","inst_table_df = inst_table_df[inst_table_df.reportDate == max(inst_table_df.reportDate)]\n","inst_table_df['symbol'] = symbol\n","inst_table_df['datefield'] = datetime.date.today()\n","\n","# Append master table to production table\n","fund_table = pandas.read_excel(\"fund_table.xlsx\")\n","if max(fund_table.reportDate) != max(fund_table_df.reportDate):\n","  fund_table = fund_table.append(fund_table_df)\n","  fund_table = fund_table[['reportDate','organization','holding','position','value','change','symbol','datefield']]\n","  fund_table.to_excel(\"fund_table.xlsx\")\n","\n","insider_table = pandas.read_excel(\"insider_table.xlsx\")\n","if max(insider_table.insider_date) != max(ins_table_df.insider_date):\n","  insider_table = insider_table.append(ins_table_df)\n","  insider_table =\tinsider_table[['insider_name','insider_trans','insider_own','insider_date','insider_value','insider_pos','insider_shrs','symbol','datefield']]\n","  insider_table.to_excel(\"insider_table.xlsx\")\n","\n","summary_table = pandas.read_excel(\"summary_table.xlsx\")\n","summary_table = summary_table.append(sum_data)\n","summary_table = summary_table[['symbol','datefield','sector','city','state','industry']]\n","summary_table = summary_table.drop_duplicates()\n","summary_table.to_excel(\"summary_table.xlsx\")\n","\n","insider_trx = pandas.read_excel(\"insider_trx.xlsx\")\n","if max(insider_trx.trx_date) != max(hold_table_df.trx_date):\n","  insider_trx = insider_trx.append(hold_table_df)\n","  insider_trx = insider_trx[['holder_name','holder_pos','holder_trx','trx_date','holder_value','holder_date','symbol','datefield']]\n","  insider_trx.to_excel(\"insider_trx.xlsx\")\n","\n","inst_table = pandas.read_excel(\"institution_table.xlsx\")\n","if max(inst_table.reportDate) != max(inst_table_df.reportDate):\n","  inst_table = inst_table.append(inst_table_df)\n","  inst_table = inst_table[['reportDate','institution','inst_pctHeld','inst_pos','inst_value','inst_pctChange','symbol','datefield']]\n","  inst_table.to_excel(\"institution_table.xlsx\")"],"metadata":{"id":"fkHxY72A15ZG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Table 9: Candlesticks"],"metadata":{"id":"zCdqGVd-rkdp"}},{"cell_type":"code","source":["'''\n","supernova catalysts (tim bohen and sykes notes)\n","1. shorts get over aggressive\n","2. a BS catalyst in a PR\n","3. discord chat rooms bashing the company\n","4. hot sector\n","5. abnormal volume\n","6. low float\n","7. former runner\n","8. low price\n","'''"],"metadata":{"id":"Y8g6Idku20Lm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["candlesticks = pandas.DataFrame()\n","\n","for symbol in symbols:\n","  headers = {\"X-RapidAPI-Key\": \"1a4e1671fdmsh8b109f9960abd33p10d082jsnf2ee61df8b81\",\"X-RapidAPI-Host\": \"apidojo-yahoo-finance-v1.p.rapidapi.com\"}\n","  url = \"https://apidojo-yahoo-finance-v1.p.rapidapi.com/stock/v2/get-chart\"\n","\n","  # daily data\n","  querystring = {\"interval\":'1d',\"symbol\": symbol,\"range\":'1y',\"region\":\"US\"}\n","  response = requests.get(url, headers=headers, params=querystring).json()\n","\n","  # variables\n","  data = pandas.DataFrame(response['chart']['result'][0]['indicators']['quote'][0])\n","  data.columns = data.columns.str.capitalize()\n","  data['Symbol'] = symbol\n","  data['datefield'] = datetime.date.today()\n","\n","  # candlesticks\n","  cndls = [Doji,DragonflyDoji,Engulfing, Hammer,HangingMan,Harami,\n","          InvertedHammer,LongleggedDoji,ShootingStar,ThreeWhiteSoldiers,ThreeBlackCrows]\n","  for c in cndls:\n","    data = c(data).compute_pattern()\n","\n","  data = data.iloc[-1]\n","  candlesticks = candlesticks.append(data)\n","\n","# Append master table to production table\n","candlestick_table = pandas.read_excel(\"candlestick_table.xlsx\")\n","if max(candlestick_table.datefield) != max(candlesticks.datefield):\n","  candlestick_table = candlestick_table.append(candlesticks)\n","  candlestick_table.to_excel(\"candlestick_table.xlsx\")"],"metadata":{"id":"Uy0_0-ZjOY34"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Table 10-12: Support/Resistance & Market Profile"],"metadata":{"id":"mkNNNviQXrle"}},{"cell_type":"code","source":["sup_res, prof, mp_df = pandas.DataFrame(), pandas.DataFrame(), pandas.DataFrame()\n","\n","for symbol in symbols:\n","  headers = {\"X-RapidAPI-Key\": \"1a4e1671fdmsh8b109f9960abd33p10d082jsnf2ee61df8b81\",\"X-RapidAPI-Host\": \"apidojo-yahoo-finance-v1.p.rapidapi.com\"}\n","  url = \"https://apidojo-yahoo-finance-v1.p.rapidapi.com/stock/v2/get-chart\"\n","\n","  # daily data\n","  querystring = {\"interval\":'1d',\"symbol\": symbol,\"range\":'1y',\"region\":\"US\"}\n","  response = requests.get(url, headers=headers, params=querystring).json()\n","  data = pandas.DataFrame(response['chart']['result'][0]['indicators']['quote'][0])\n","  data.columns = data.columns.str.capitalize()\n","\n","  # market profile\n","  mp = MarketProfile(data)\n","  mp_slice = mp[data.index.min():data.index.max()]\n","  support_resistance = pandas.DataFrame(mp_slice.high_value_nodes)\n","  support_resistance['symbol'] = symbol\n","  support_resistance['datefield'] = datetime.date.today()\n","  profile = pandas.DataFrame(mp_slice.profile)\n","  profile['symbol'] = symbol\n","  profile['datefield'] = datetime.date.today()\n","\n","  try:\n","    opl, oph = mp_slice.open_range()[0] , mp_slice.open_range()[1]\n","  except:\n","    opl,oph = -1, -1\n","\n","  try:\n","    ibl,ibh = mp_slice.initial_balance()[0], mp_slice.initial_balance()[1]\n","  except:\n","    ibl,ibh = -1, -1\n","\n","  # convert to dataframe\n","  mp = pandas.DataFrame(\n","    { 'symbol': symbol,\n","      'datefield': datetime.date.today(),\n","      'balanced_target': mp_slice.balanced_target,\n","      'value_area_low': mp_slice.value_area[0],\n","      'value_area_high': mp_slice.value_area[1],\n","      'profile_range_low': mp_slice.profile_range[0],\n","      'profile_range_high': mp_slice.profile_range[1],\n","      'poc_price': mp_slice.poc_price,\n","      'open_range_low': opl,\n","      'open_range_high': oph,\n","      'initial_bal_low': ibl,\n","      'initial_bal_high': ibh\n","    },index = [0])\n","\n","  sup_res = sup_res.append(support_resistance)\n","  prof = prof.append(profile)\n","  mp_df = mp_df.append(mp)\n","\n","sup_res = sup_res.reset_index()\n","prof = prof.reset_index()\n","mp_df = mp_df.reset_index()\n","\n","# Append master table to production table\n","sup_res_table = pandas.read_excel(\"support_resistance_table.xlsx\")\n","if max(sup_res_table.datefield) != max(sup_res.datefield):\n","  sup_res_table = sup_res_table.append(sup_res)\n","  sup_res_table = sup_res_table[['Close','Volume','symbol','datefield']]\n","  sup_res_table.to_excel(\"support_resistance_table.xlsx\")\n","\n","m_p_sum = pandas.read_excel(\"market_profile_summary.xlsx\")\n","if max(m_p_sum.datefield) != max(prof.datefield):\n","  m_p_sum = m_p_sum.append(prof)\n","  m_p_sum = m_p_sum[['Close','Volume','symbol','datefield']]\n","  m_p_sum.to_excel(\"market_profile_summary.xlsx\")\n","\n","m_p_det = pandas.read_excel(\"market_profile_detail.xlsx\")\n","if max(m_p_det.datefield) != max(mp_df.datefield):\n","  m_p_det = m_p_det.append(mp_df)\n","  m_p_det = m_p_det[['symbol', 'datefield', 'balanced_target', 'value_area_low','value_area_high', 'profile_range_low', 'profile_range_high',\n","                      'poc_price', 'open_range_low', 'open_range_high', 'initial_bal_low','initial_bal_high']]\n","  m_p_det.to_excel(\"market_profile_detail.xlsx\")"],"metadata":{"id":"PeHKU7wzXuwb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Table 13: Technical Indicators"],"metadata":{"id":"u16lNSwe6XFD"}},{"cell_type":"code","source":["tech_ind = pandas.DataFrame()\n","\n","for symbol in symbols:\n","  headers = {\"X-RapidAPI-Key\": \"1a4e1671fdmsh8b109f9960abd33p10d082jsnf2ee61df8b81\",\"X-RapidAPI-Host\": \"apidojo-yahoo-finance-v1.p.rapidapi.com\"}\n","  url = \"https://apidojo-yahoo-finance-v1.p.rapidapi.com/stock/v2/get-chart\"\n","\n","  # daily data\n","  querystring = {\"interval\":'1d',\"symbol\": symbol,\"range\":'1y',\"region\":\"US\"}\n","  response = requests.get(url, headers=headers, params=querystring).json()\n","  data = pandas.DataFrame(response['chart']['result'][0]['indicators']['quote'][0])\n","  data.columns = data.columns.str.capitalize()\n","\n","  # technicals\n","  data = add_all_ta_features(data, open=\"Open\", high=\"High\", low=\"Low\", close=\"Close\", volume=\"Volume\",fillna=True)\n","  data['Symbol'] = symbol\n","  data['Datefield'] = datetime.date.today()\n","  data['cndl_clr'] = list(map(lambda c, o: 1 if c - o >= 0 else -1, data.Close, data.Open))\n","  data['vol_acc_ind'] = sum(data.Volume * data.cndl_clr)\n","  data['vol_acc_3d'] = data.vol_acc_ind.rolling(3).sum()\n","  data['vol_acc_4d'] = data.vol_acc_ind.rolling(4).sum()\n","  data['vol_acc_5d'] = data.vol_acc_ind.rolling(5).sum()\n","  data['vol_acc_10d'] = data.vol_acc_ind.rolling(10).sum()\n","\n","  data['sma_10d'] = data.Close.rolling(10).mean()\n","  data['sma_20d'] = data.Close.rolling(20).mean()\n","  data['sma_50d'] = data.Close.rolling(50).mean()\n","  data['sma_100d'] = data.Close.rolling(100).mean()\n","  data['sma_200d'] = data.Close.rolling(200).mean()\n","\n","  data['ave_vol_3d'] = data.Volume.rolling(3).mean()\n","  data['ave_vol_5d'] = data.Volume.rolling(5).mean()\n","  data['ave_vol_10d'] = data.Volume.rolling(10).mean()\n","  data['ave_vol_30d'] = data.Volume.rolling(30).mean()\n","  data['ave_vol_60d'] = data.Volume.rolling(60).mean()\n","  data['ave_vol_90d'] = data.Volume.rolling(90).mean()\n","\n","  data['high_1d'] = data.High.rolling(1).max()\n","  data['high_3d'] = data.High.rolling(3).max()\n","  data['high_5d'] = data.High.rolling(5).max()\n","  data['high_10d'] = data.High.rolling(10).max()\n","  data['high_15d'] = data.High.rolling(15).max()\n","  data['high_20d'] = data.High.rolling(20).max()\n","  data['high_30d'] = data.High.rolling(30).max()\n","  data['high_60d'] = data.High.rolling(60).max()\n","  data['high_90d'] = data.High.rolling(90).max()\n","  data['high_120d'] = data.High.rolling(120).max()\n","\n","  data['low_1d'] = data.Low.rolling(1).min()\n","  data['low_3d'] = data.Low.rolling(3).min()\n","  data['low_5d'] = data.Low.rolling(5).min()\n","  data['low_10d'] = data.Low.rolling(10).min()\n","  data['low_15d'] = data.Low.rolling(15).min()\n","  data['low_20d'] = data.Low.rolling(20).min()\n","  data['low_30d'] = data.Low.rolling(30).min()\n","  data['low_60d'] = data.Low.rolling(60).min()\n","  data['low_90d'] = data.Low.rolling(90).min()\n","  data['low_120d'] = data.Low.rolling(120).min()\n","\n","  data = data.iloc[-1]\n","  tech_ind = tech_ind.append(data)\n","\n","# Technicals\n","technicals = pandas.read_excel(\"technical_data.xlsx\")\n","if max(tech_ind.Datefield) != max(technicals.Datefield):\n","  technicals = technicals.append(tech_ind)\n","  technicals = technicals[['Close', 'Volume', 'Open', 'High', 'Low', 'volume_adi', 'volume_obv',\n","          'volume_cmf', 'volume_fi', 'volume_em', 'volume_sma_em', 'volume_vpt',\n","          'volume_vwap', 'volume_mfi', 'volume_nvi', 'volatility_bbm',\n","          'volatility_bbh', 'volatility_bbl', 'volatility_bbw', 'volatility_bbp',\n","          'volatility_bbhi', 'volatility_bbli', 'volatility_kcc',\n","          'volatility_kch', 'volatility_kcl', 'volatility_kcw', 'volatility_kcp',\n","          'volatility_kchi', 'volatility_kcli', 'volatility_dcl',\n","          'volatility_dch', 'volatility_dcm', 'volatility_dcw', 'volatility_dcp',\n","          'volatility_atr', 'volatility_ui', 'trend_macd', 'trend_macd_signal',\n","          'trend_macd_diff', 'trend_sma_fast', 'trend_sma_slow', 'trend_ema_fast',\n","          'trend_ema_slow', 'trend_vortex_ind_pos', 'trend_vortex_ind_neg',\n","          'trend_vortex_ind_diff', 'trend_trix', 'trend_mass_index', 'trend_dpo',\n","          'trend_kst', 'trend_kst_sig', 'trend_kst_diff', 'trend_ichimoku_conv',\n","          'trend_ichimoku_base', 'trend_ichimoku_a', 'trend_ichimoku_b',\n","          'trend_stc', 'trend_adx', 'trend_adx_pos', 'trend_adx_neg', 'trend_cci',\n","          'trend_visual_ichimoku_a', 'trend_visual_ichimoku_b', 'trend_aroon_up',\n","          'trend_aroon_down', 'trend_aroon_ind', 'trend_psar_up',\n","          'trend_psar_down', 'trend_psar_up_indicator',\n","          'trend_psar_down_indicator', 'momentum_rsi', 'momentum_stoch_rsi',\n","          'momentum_stoch_rsi_k', 'momentum_stoch_rsi_d', 'momentum_tsi',\n","          'momentum_uo', 'momentum_stoch', 'momentum_stoch_signal', 'momentum_wr',\n","          'momentum_ao', 'momentum_roc', 'momentum_ppo', 'momentum_ppo_signal',\n","          'momentum_ppo_hist', 'momentum_pvo', 'momentum_pvo_signal',\n","          'momentum_pvo_hist', 'momentum_kama', 'others_dr', 'others_dlr',\n","          'others_cr','Symbol','Datefield','vol_acc_3d','vol_acc_4d',\n","          'vol_acc_5d','vol_acc_10d','sma_10d','sma_20d','sma_50d','sma_100d','sma_200d',\n","          'ave_vol_3d','ave_vol_5d','ave_vol_10d','ave_vol_30d','ave_vol_60d','ave_vol_90d',\n","          'high_1d','high_3d','high_5d','high_10d','high_15d','high_20d','high_30d','high_60d',\n","          'high_90d','high_120d','low_1d','low_3d','low_5d','low_10d','low_15d','low_20d','low_30d','low_60d',\n","          'low_90d','low_120d']]\n","  technicals.to_excel(\"technical_data.xlsx\")"],"metadata":{"id":"leSDMhmF6cH0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Table 14: SEC Filings"],"metadata":{"id":"iC9y7j8CluxL"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Small Caps/Functions\n","path_to_module = '/content/drive/MyDrive/Small Caps/Functions'\n","sys.path.append(path_to_module)\n","\n","import sec_filings, sec_filings_keywords\n","from sec_filings import get_sec_filing\n","from sec_filings_keywords import get_sec_filing_keyword"],"metadata":{"id":"BBJBedMbxTNE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36'}\n","forms_ = ['424b3','424b4','424b5','s-3','f-3','3','4','sc+13g','sc+13d','s-1','f-1']\n","forms_2 = ['6-k','8-k']\n","keywords = ['reverse split','reverse stock split',                                                                            # reverse split\n","            '3.01 Notice',                                                                                                    # delist notice\n","            'Item 5.02','Board of Directors','Departure of Director','Appointment of New Director','Election of Directors',   # director change\n","            'annual meeting of stockholders','annual meeting of shareholders','elected to the Board',                         # director change\n","            'Annual Meeting the Company’s stockholders',                                                                      # director change\n","            'Item 4.01','Appointment of Auditor','independent registered public accounting firm',                             # new accountant\n","            'LLP as auditor','independent auditor']\n","filings = pandas.DataFrame()\n","pandas.set_option('display.max_colwidth', None)\n","\n","# sec filings\n","for form in forms_:\n","  links = get_sec_filing(form,0)\n","  for link in range(0,len(links)):\n","    data = [links[link][0],links[link][1],links[link][2],form]\n","    df = pandas.DataFrame(data).T\n","    df.columns = ['cik','datefield','url','filing_type']\n","    df['time'] = df.datefield.apply(lambda a: a.time())\n","    df['datefield'] = df.datefield.apply(lambda a: a.date())\n","    df['keyword'] = 'NA'\n","    df = df[['cik','datefield','time','url','filing_type','keyword']]\n","    filings = filings.append(df)\n","\n","# sec filings, keywords\n","for form in forms_2:\n","  links = get_sec_filing(form,0)\n","  for word in keywords:\n","    symbolss = get_sec_filing_keyword(links, word)\n","    symbolss = pandas.DataFrame(symbolss, columns = ['cik','datefield','keyword'])\n","    symbolss['filing_type'] = form\n","    symbolss['time'] = symbolss.datefield.apply(lambda a: a.time())\n","    symbolss['datefield'] = symbolss.datefield.apply(lambda a: a.date())\n","    symbolss['url'] = 'NA'\n","    symbolss = symbolss[['cik','datefield','time','url','filing_type','keyword']]\n","    filings = filings.append(symbolss)\n","\n","filings = filings.drop_duplicates(keep = 'first')\n","\n","# convert cik to ticker\n","headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36'}\n","url = 'https://www.sec.gov/files/company_tickers.json'\n","r = requests.get(url,headers=headers)\n","\n","with open(\"sample.html\", \"w\") as html_file:\n","    html_file.write(r.text)\n","\n","with open(\"sample.html\", \"r\") as html_file:\n","    html = html_file.read()\n","\n","idx_lb = [i for i in range(len(html)) if html.startswith(\"{\", i)]\n","idx_lb = idx_lb[1:]\n","idx_ub = [i for i in range(len(html)) if html.startswith(\"}\", i)]\n","idx_ub = idx_ub[:-1]\n","ticker_table = []\n","\n","for lb,ub in zip(idx_lb,idx_ub):\n","  line_of_data = html[lb:ub]\n","  line_of_data_sp = list(line_of_data.split(\",\"))\n","  idx1 = line_of_data_sp[0].find(':') + 1\n","  idx2 = line_of_data_sp[1].find(':') + 1\n","  cik = line_of_data_sp[0][idx1:]\n","  ticker = line_of_data_sp[1][idx2:].replace('\"','')\n","  ticker_table.append((cik,ticker))\n","\n","ticker_table = pandas.DataFrame(ticker_table,columns = ['cik','symbol'])\n","filings = filings.merge(ticker_table, how = 'inner', left_on = 'cik', right_on = 'cik')\n","\n","# Change directory back\n","%cd /content/drive/MyDrive/Small Caps/Database\n","path_to_module = '/content/drive/MyDrive/Small Caps/Database'\n","sys.path.append(path_to_module)\n","\n","# Append new file to existing datatable\n","sec_filings = pandas.read_excel(\"sec_filings_table.xlsx\")\n","if max(sec_filings.datefield) != max(filings.datefield):\n","  sec_filings = sec_filings.append(filings)\n","  sec_filings = sec_filings[['cik','datefield','time','url','filing_type','keyword','symbol']]\n","  sec_filings.to_excel(\"sec_filings_table.xlsx\")\n","\n","# incorporation state"],"metadata":{"id":"KMxCST7KlxV5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Table 15: News"],"metadata":{"id":"_0bJ1BN2K7ov"}},{"cell_type":"code","source":["news_table_df = pandas.DataFrame()\n","pandas.set_option('display.max_colwidth', None)\n","\n","for symbol in symbols:\n","  url = \"https://apidojo-yahoo-finance-v1.p.rapidapi.com/news/v2/list\"\n","  querystring = {\"region\":\"US\",\"snippetCount\":\"28\",\"s\":symbol}\n","  payload = \"Pass in the value of uuids field returned right in this endpoint to load the next page, or leave empty to load first page\"\n","  headers = {\"content-type\": \"text/plain\",\"X-RapidAPI-Key\": \"1a4e1671fdmsh8b109f9960abd33p10d082jsnf2ee61df8b81\",\"X-RapidAPI-Host\": \"apidojo-yahoo-finance-v1.p.rapidapi.com\"}\n","  response = requests.post(url, data=payload, headers=headers, params=querystring).json()\n","\n","  for i in range(0, len(response['data']['main']['stream'])):\n","    datefield = response['data']['main']['stream'][i]['content']['pubDate']\n","    datefield = parser.parse(datefield)\n","    date_ = datetime.date(datefield.year,datefield.month,datefield.day)\n","    datefield = datetime.datetime(datefield.year,datefield.month,datefield.day,datefield.hour,datefield.minute,datefield.second)\n","\n","    if date_ == datetime.date.today():\n","      try:\n","        # convert to dataframe\n","        news_table = pandas.DataFrame(\n","          { 'symbol': symbol,\n","            'datefield': datetime.date.today(),\n","            'storytitle': response['data']['main']['stream'][i]['content']['title'],\n","            'pub_time': datefield.time(),\n","            'storyurl': response['data']['main']['stream'][i]['content']['clickThroughUrl']['url'],\n","            'newsource': response['data']['main']['stream'][i]['content']['provider']['displayName']\n","          },index = [0])\n","        news_table_df = news_table_df.append(news_table)\n","      except:\n","        news_table = pandas.DataFrame(\n","          { 'symbol': symbol,\n","            'datefield': datetime.date.today(),\n","            'storytitle': response['data']['main']['stream'][i]['content']['title'],\n","            'pub_time': datefield.time(),\n","            'storyurl': response['data']['main']['stream'][i]['content']['previewUrl'],\n","            'newsource': response['data']['main']['stream'][i]['content']['provider']['displayName']\n","          },index = [0])\n","        news_table_df = news_table_df.append(news_table)\n","\n","# Append new file to existing datatable\n","news = pandas.read_excel(\"news_table.xlsx\")\n","if max(sec_filings.datefield) != max(filings.datefield):\n","  news = news.append(news_table_df)\n","  news = news[['symbol','datefield','storytitle','pub_time','storyurl','newsource']]\n","  news.to_excel(\"news_table.xlsx\")"],"metadata":{"id":"r4RvUIKlK9_8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Table 16: Market Table"],"metadata":{"id":"t2gGRtXUpCws"}},{"cell_type":"code","source":["dailytable = pandas.DataFrame()\n","\n","for symbol in ['SPY','DIA','QQQ', 'XLE', 'XLF', 'XLU', 'XLI', 'GDX', 'XLK', 'XLV',\n","               'XLY', 'XLP', 'XLB', 'XOP', 'IYR', 'XHB', 'ITB', 'VNQ', 'GDXJ',\n","               'IYE', 'OIH', 'XME', 'XRT', 'SMH', 'IBB', 'KBE', 'KRE', 'XTL']:\n","\n","  # connect to Yahoo Finance API\n","  headers = {\"X-RapidAPI-Key\": \"1a4e1671fdmsh8b109f9960abd33p10d082jsnf2ee61df8b81\",\"X-RapidAPI-Host\": \"apidojo-yahoo-finance-v1.p.rapidapi.com\"}\n","  url = \"https://apidojo-yahoo-finance-v1.p.rapidapi.com/stock/v2/get-chart\"\n","\n","  # daily data\n","  querystring = {\"interval\":'1d',\"symbol\": symbol,\"range\":'1y',\"region\":\"US\"}\n","  response = requests.get(url, headers=headers, params=querystring).json()\n","\n","  # variables\n","  v = response['chart']['result'][0]['indicators']['quote'][0]['volume'][-1]\n","  h = response['chart']['result'][0]['indicators']['quote'][0]['high'][-1]\n","  c = response['chart']['result'][0]['indicators']['quote'][0]['close'][-1]\n","  dv = v * c\n","  o = response['chart']['result'][0]['indicators']['quote'][0]['open'][-1]\n","  l = response['chart']['result'][0]['indicators']['quote'][0]['low'][-1]\n","  a_c = response['chart']['result'][0]['indicators']['adjclose'][0]['adjclose'][-1]\n","  pc = response['chart']['result'][0]['indicators']['quote'][0]['close'][-2]\n","  h_52wk = max(response['chart']['result'][0]['indicators']['quote'][0]['high'])\n","  l_52wk = min(response['chart']['result'][0]['indicators']['quote'][0]['low'])\n","\n","  # convert to dataframe\n","  data = pandas.DataFrame(\n","  {'symbol': symbol,\n","   'datefield': datetime.date.today(),\n","   'volume': v,\n","   'dollar_volume': dv,\n","   'high': h,\n","   'open': o,\n","   'low': l,\n","   'close': c,\n","   'adj_close': a_c,\n","   'prev_close': pc,\n","   'high_52wk': h_52wk,\n","   'low_52wk': l_52wk\n","  },index = [0])\n","\n","  dailytable = dailytable.append(data)\n","\n","for symbol in ['BTC-USD','ETH-USD','USDT-USD','BNB-USD','XRP-USD','SOL-USD','USDC-USD','ADA-USD','DOGE-USD','AVAX-USD']:\n","\n","  btc = yf.download(symbol)\n","  pc = btc.Close.iloc[-2]\n","  h_52wk = btc.High.iloc[-365].max()\n","  l_52wk = btc.Low.iloc[-365].min()\n","  btc = btc.iloc[-1]\n","\n","  # convert to dataframe\n","  data = pandas.DataFrame(\n","  {'symbol': symbol,\n","   'datefield': datetime.date.today(),\n","   'volume': btc.Volume,\n","   'dollar_volume': btc.Volume * btc.Close,\n","   'high': btc.High,\n","   'open': btc.Open,\n","   'low': btc.Low,\n","   'close': btc.Close,\n","   'adj_close': btc['Adj Close'],\n","   'prev_close': pc,\n","   'high_52wk': h_52wk,\n","   'low_52wk': l_52wk\n","  },index = [0])\n","\n","  dailytable = dailytable.append(data)\n","\n","# Append master tables to production tables\n","market_table = pandas.read_excel(\"market_table.xlsx\")\n","if max(key_statistics.datefield) != max(dailytable.datefield):\n","  market_table = market_table.append(dailytable)\n","  market_table.to_excel(\"market_table.xlsx\")"],"metadata":{"id":"mdYkk5oQpEP7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Table 17: Chat Room Table"],"metadata":{"id":"U49cFdJXH-KJ"}},{"cell_type":"code","source":["url = \"https://twitter241.p.rapidapi.com/search\"\n","querystring = {\"query\":\"$SHOT\",\"count\":\"1000\",\"type\":\"Top\"}\n","headers = {\"X-RapidAPI-Key\": \"1a4e1671fdmsh8b109f9960abd33p10d082jsnf2ee61df8b81\",\"X-RapidAPI-Host\": \"twitter241.p.rapidapi.com\"}\n","response = requests.get(url, headers=headers, params=querystring).json()\n","response['result']['timeline']['instructions'] # API is complex ...\n","\n","#date\n","#ticker\n","#Chat_room_ind (reddit, twitter, stocktwits…)\n","#msg_vol\n","#likes_vol\n","#dislikes_vol\n","#comments_vol\n","#Sentiment\n","#User\n","#user_followers\n","\n","# custom code to develop using:\n","# 1. twitter's developer API\n","# 2. reddit's developer API and scrape wallstreetbets\n","# 3. discord developer API"],"metadata":{"id":"yWL1qZtoIA1w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Table 18: Short Squeeze Table"],"metadata":{"id":"0rU6XWqE9hyq"}},{"cell_type":"code","source":["# ticker\n","# date\n","#time-to-cover: shares short > 5x average daily volume\n","#shares short as a % of float > 10%\n","# no. shares short rising daily\n","#Low_float_ind\n","# Finding locates for shorts (determines share availability)\n","# Ensuring shorts locates are cheap\n","# short availability : https://www.quantconnect.com/datasets/us-equities-short-availability"],"metadata":{"id":"iCFqL2s09md7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Table 19: Pattern Stats Table"],"metadata":{"id":"Ka7cQ6N49-NK"}},{"cell_type":"code","source":["#ticker\n","#date\n","#cup_and_handle\n","#ascending_triangle\n","#descending_triangle\n","#converging_triangle\n","#stair_stepper\n","#fgd_breakout\n","#frd_breakdown\n","#multi_day_runner\n","#supernova\n","#cliff_dive\n","#double_top_ind\n","#double_bottom_ind\n","#morning_panic_ind\n","#morning_spike_ind\n","#dip_buy\n","#head_shoulders\n","#inverse_cup_handle\n","#reverse_stair_stepper\n","#dead_pump_bounce\n","#fgd_ind\n","#sgd_ind\n","#frd_ind\n","#srd_ind\n","#breakout_ind\n","#Breakdown_ind\n","#over_extended_ind\n","#lower_highs_ind\n","#higher_lows_ind\n","#consolidation_ind"],"metadata":{"id":"i9SsgAPE-A68"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Resources"],"metadata":{"id":"JOBAWnye-MlE"}},{"cell_type":"code","source":["https://www.quantconnect.com/datasets/nasdaq-data-link\n","https://www.quantconnect.com/datasets"],"metadata":{"id":"WRP0qKzL-NSd"},"execution_count":null,"outputs":[]}]}